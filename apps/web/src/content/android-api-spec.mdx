import { Callout } from 'nextra/components';

# Android API Spec

## LeapClient

The entrypoint of LEAP SDK. It doesn’t hold any data.

```kotlin
object LeapClient {
	suspend fun loadModel(path: String): ModelRunner
}
```

### `loadModel`

This function can be called from UI thread. The `path` should be a local path pointing to model bundle file. The app needs to hold the model runner object return by this function until there is no need to interact with the model anymore. See [ModelRunner](https://www.notion.so/ModelRunner-1f2cbef042ad80b8a0ffeb5df20762b0?pvs=21) for more details.

<Callout type="info">
  {' '}
  The function will throw `LeapModelLoadingException` if LEAP fails to load the model.
</Callout>

## Conversation

The instance of a conversation, which hosts the message history and states that needed to be used by model runner for generation.

While this conversation instance holds the data necessary for model runner to perform generation, the app still needs to maintain the UI state of the message history representation by itself.

```kotlin
interface Conversation {
	// Chat history
	val history: List<ChatMessage>
	// Generating response from a text input as user message
	fun generateResponse(userTextMessage: String): Flow<MessageResponse>
	// Generating response from an arbitrary new message
	fun generateResponse(message: ChatMessage): Flow<MessageResponse>
}
```

### `generateResponse`

Only `generateResponse(message: ChatMessage)` is the real implementation of response generation. Others are wrapper over this function. It can be called from UI thread.

The return value is a Kotlin [asynchronous flow](https://kotlinlang.org/docs/flow.html). The generation will **not** start until the flow is collected (following the convention of flows). Refer to [Android document](https://developer.android.com/topic/libraries/architecture/coroutines) on how to properly handle the flow with lifecycle-aware components.

`MessageResponse` instance will be emitted from this flow, which contains the chunk of data generated from the model.

<Callout type="info">
  {' '}
  Errors will be thrown as `LeapGenerationException` in the stream. Use `.catch` to capture errors
  from the generation.{' '}
</Callout>
<Callout type="warning">
  {' '}
  If there is already a running generation, further generation requests are blocked until the
  current generation is done. However, there is no guarantee that the requests come first will be
  processed first.{' '}
</Callout>

### Cancellation of the generation

Generation will be stoped when the coroutine job that runs the flow is canceled, and the generation may (no guarantee) keep going as long as the job of the flow is still active.

We hence highly recommend the generation to be started within a coroutine scope associated with a lifecycle-aware component so that the generation can be stopped if the lifecycle-aware components are destroyed. Here is an example.

```kotlin
job = lifecycleScope.launch {
  conversation.generateResponse(userInput)
  .onEach {
     when (it) {
       is MessageResponse.Chunk -> {
         Log.d(TAG, it.text)
       }
       is MessageResponse.Complete -> {
         Log.d(TAG, "Generation is done!")
       }
       else -> {}
     }
  }
  .collect()

// Stop the generation by canceling the job
job.cancel()
```

### `history`

`history` value field will return a **copy** of the chat message history. Any mutations to its return value will **not** change the internal state of the generation. If there is an ongoing generation, the partial message may not be available in the return value of this field. However, it is guaranteed that when `MessageResponse.Complete` is received and when the flow is completed, the history value field will be updated to have the latest message.

### Creation

Instance of this class should not be directly initiated. It should be created by the `ModelRunner` instance.

### Lifetime

While it keeps the history and state that needed by the model runner to generate content, its generation function relies on the model runner that creates it. As a result, if model runner that created the conversation instance has been destroyed, this instance also cannot do generation anymore.

## ModelRunner

An instance of model loaded in the memory. Conversation instances should be created from it. Each inference stack will provide a model runner implementation and the LEAP SDK. The application needs to own the model runner object. If the model runner object is destroyed, the ongoing generations may fail.

If you need your model runner to survive after the destroy of activities, you may need to wrap it in an [Android Service](https://developer.android.com/develop/background-work/services).

```kotlin
interface ModelRunner {
  // create a conversation instance
	fun createConversation(systemPrompt: String? = null): Conversation

	// create a conversation from chat message history
	fun createConversationFromHistory(history: List<ChatMessage>): Conversation

	// unload the model: the runner cannot be used after unload is called.
	suspend fun unload()


	// Start generation from the conversation instance.
	fun generateFromConversation(
		conversation: Conversation,
    callback: GenerationCallback,
  ): GenerationHandler
}
```

### `createConversation`

Factory method to create a conversation instance based on this model runner. As a result, the model runner instance will be used for any generation around the created conversation instance. The model runner will have access to the internal state of the created conversation.

If the model runner is unloaded, any conversation instances created from the model runner will be read only.

### `createConversationFromHistory`

This factory method will create a conversation object with the chat history. It can be used to restore the conversation from persistent storage while ensuring that a living model runner is backing it.

### `unload`

Unload the model from the memory. The model runner will not be able to perform generation once this method is invoked. Exception may be thrown in the ongoing generation. It is app developer’s responsibility to ensure that the unload is called after all generation is done.

### `generateFromConversation`

This function is **not** recommended to be called by the app directly. It is the interface for the model runner implementation to expose the generation ability to LEAP SDK. `Conversation.generateResponse` is the better wrapper of this method, which relies on Kotlin coroutines to connect with lifecycle-aware components.

<Callout type="warning">
  {' '}
  This function may block the thread. Please call it outside the main thread.
</Callout>

## ChatMessage

Aata class that is compatible with the message object in OpenAI chat completion API.

```kotlin
data class ChatMessage(
  val role: Role,
  val content: List<ChatMessageContent>
  val reasoningContent: String? = null
) {
  fun toJSONObject(): JSONObject
}

ChatMessage.fromJSONObject(obj: JSONObject): ChatMessage
```

### Fields

- `role`: The role of this message.
- `content`: A list of message contents. Each element is an instance of [`ChatMessageContent`](#chatmessagecontent).
- `reasoningContent`: The reasoning content generated by the reasoning models. Only messages generated by reasoning models will have this field. For other models or other roles, this field should be null.

### `toJSONObject`

Return a JSONObject that represents the chat message. The return object is compatible with `ChatCompletionRequestMessage` from OpenAI API. It contains 2 fields: `role` and `content` .

### `fromJSONObject`

Construct a `ChatMessage` instance from a `JSONObject`. Not all JSON object variants in `ChatCompletionRequestMessage` of OpenAI API are acceptable. As for now, `role` supports user, system and assistant. `content` can be a string or an array.

<Callout type="info">
  {' '}
  `LeapSerializationException` will be thrown if the provided JSONObject cannot be recognized as a
  message.{' '}
</Callout>

## ChatMessage.Role

Roles of the chat messages, which is following the OpenAI API definition. It is an enum with following values:

```kotlin
enum class Role(val type: String) {
  SYSTEM("system"),
  USER("user"),
  ASSISTANT("assistant"),
}
```

- `SYSTEM`: The system prompt. It is generally the first message to provide guidance on how the model should behave.
- `USER`: The input from users.
- `ASSISTANT`: Generated output from the model.

## ChatMessageContent

Data class that is compatible with the content object in OpenAI chat completion API. It is an sealed class.

```kotlin
abstract class ChatMessageContent {
	 fun clone(): ChatMessageContent
	 fun toJSONObject(): JSONObject
}
fun ChatMessageContent.fromJSONObject(obj: JSONObject): ChatMessageContent
```

- `toJSONObject` returns an OpenAI API compatible content object (with a `type` field and the real content fields)
- `fromJSONObject` receives an OpenAI API compatible content object to build a message content. Not all OpenAI content objects are accepted.

<Callout type="info">
  {' '}
  `LeapSerializationException` will be thrown if the provided JSONObject cannot be recognized as a
  message.{' '}
</Callout>

Currently, only following content types are supported:

- `Text` : pure text content.

## MessageResponse

The response generated from models. The generation may takes a long time to finish, so the generated text will be sent out as “chunks”. When the generation completes, a complete response object will be sent out. This is a sealed class where only following options are available:

```kotlin
sealed class MessageResponse {
    class Chunk(val text: String) : MessageResponse()
    class ReasoningChunk(val reasoning: String) : MessageResponse()
    class Complete(val fullMessage: ChatMessage, val finishReason: GenerationFinishReason) : MessageResponse()
}
```

- `Chunk` is a piece of generated text.
- `ReasoningChunk` is a piece of generated reasoning text. It will be emitted only by reasoning models.
- `Complete` indicates the completion of a generation. The `fullMessage` field contains all the content the generated from this round of generation, and the `finishReason` indicates why the generation is done.

## Error Handling

All errors are thrown as `LeapException` . It has following subclasses:

- `LeapModelLoadingException` : error in loading the model
- `LeapGenerationException` : error in generating contents
- `LeapSerializationException` : error in serializing / deserializing data.
